{

# general inputs

'env_name'      :   'mjrl_reacher_7dof-v0',
'seed'          :   123,
'debug_mode'    :   False,
'num_iter'      :   100,
'paths_per_iter':   5,
'eval_rollouts' :   20,
'num_models'    :   4,
'exp_notes'     :   'H=50, skip=4',
'save_freq'     :   5,
'device'        :   'cpu',

# dynamics learning

'hidden_size'   :   (256, 256),
'activation'    :   'relu',
'fit_lr'        :   1e-3,
'fit_wd'        :   0.0,
'max_paths'     :   500,
'fit_mb_size'   :   64,
'fit_epochs'    :   10,
'refresh_fit'   :   False,

# initial data

'init_log_std'  :   -0.5,
'min_log_std'   :   -2.5,
'n_init_paths'  :   50,
'use_demos'     :   False,
'demo_file'     :   None,

# NPG params

'policy_size'   :   (64, 64),
'inner_steps'   :   10,
'step_size'     :   0.05,
'update_paths'  :   200,
'horizon'       :   50,
'hvp_frac'      :   None,

}